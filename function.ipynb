{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def set_image_dpi(image_path, dpi=300, output_path=None):\n",
    "    # Open the image using Pillow\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Set the DPI resolution\n",
    "    img.info[\"dpi\"] = (dpi, dpi)\n",
    "\n",
    "    # Save the image with the new DPI resolution\n",
    "    if output_path:\n",
    "        img.save(output_path, dpi=(dpi, dpi))\n",
    "    else:\n",
    "        img.save(image_path, dpi=(dpi, dpi))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'input_image.jpg' with the path to your input image\n",
    "    input_image_path = r\"C:\\Users\\Sam\\Desktop\\project\\ocr_code\\Automatic-test-scoring-system\\scanned_sheets\\sheet1.jpg\"\n",
    "\n",
    "    # Replace 'output_image.jpg' with the desired path for the output image (optional)\n",
    "    output_image_path = r\"C:\\Users\\Sam\\Desktop\\project\\ocr_code\\Automatic-test-scoring-system\\scanned_sheets\\resolved_sheet1.jpg\"\n",
    "\n",
    "    # Set the DPI resolution to 300\n",
    "    set_image_dpi(input_image_path, dpi=300, output_path=output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import pythoncom\n",
    "import win32com.client as wia\n",
    "def create_temp_folder():\n",
    "    temp_dir = 'scanned_sheets'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    return temp_dir\n",
    "def scan_without_dialog(scanner_name):\n",
    "    pythoncom.CoInitialize()\n",
    "    try:\n",
    "        # Create a WIA device manager\n",
    "        device_manager = wia.Dispatch(\"WIA.DeviceManager\")\n",
    "\n",
    "        # Get the collection of available scanner devices\n",
    "        device_infos = device_manager.DeviceInfos\n",
    "\n",
    "        # Find the scanner with the specified name\n",
    "        scanner = None\n",
    "        for device_info in device_infos:\n",
    "            if device_info.Properties(\"Name\").Value == scanner_name:\n",
    "                scanner = device_info.Connect()\n",
    "                break\n",
    "\n",
    "        if scanner is None:\n",
    "            print(f\"Scanner '{scanner_name}' not found.\")\n",
    "            return\n",
    "\n",
    "        # Set the desired scanning parameters (e.g., DPI, color mode, format)\n",
    "        # For example, set the scan resolution to 300 DPI and use color scanning\n",
    "        properties = scanner.Items[1].Properties\n",
    "        for prop in properties:\n",
    "            if prop.Name == '6146':  # 6146 is the property ID for scan resolution (DPI)\n",
    "                prop.Value = 300\n",
    "            elif prop.Name == '6147':  # 6147 is the property ID for color mode (1: Color, 2: Grayscale, 4: Black and White)\n",
    "                prop.Value = 1\n",
    "\n",
    "        # Perform the scan and retrieve the scanned image\n",
    "        image = scanner.Items[1].Transfer()\n",
    "        temp_dir = create_temp_folder()\n",
    "        \n",
    "        # Save the scanned image to a file inside the temporary folder\n",
    "        image_path=f\"{temp_dir}/sheet9.jpg\"\n",
    "        image.SaveFile(image_path)\n",
    "\n",
    "        pythoncom.CoUninitialize()\n",
    "        return image_path\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, print an error message, etc.\n",
    "        print(\"Error:\", e)\n",
    "        pythoncom.CoUninitialize()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (-2147352567, 'Exception occurred.', (0, 'WIA.ImageFile.1', 'The file exists.\\r\\n', None, 0, -2147024816), None)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path=scan_without_dialog(scanner_name = \"HP Laser MFP 131 133 135-138\")\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client as wia\n",
    "\n",
    "# Create a WIA com object\n",
    "wia_obj = wia.Dispatch(\"WIA.CommonDialog\")\n",
    "\n",
    "# Show the scanning dialog and retrieve the scanned image\n",
    "image = wia_obj.ShowAcquireImage()\n",
    "\n",
    "# Save the scanned image to a file\n",
    "image.SaveFile(\"secanned_image.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "def create_temp_folder():\n",
    "    temp_dir = 'scanned_sheets'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    return temp_dir\n",
    "\n",
    "def scan_without_dialog(scanner_name):\n",
    "    # Create a WIA device manager\n",
    "    device_manager = wia.Dispatch(\"WIA.DeviceManager\")\n",
    "\n",
    "    # Get the collection of available scanner devices\n",
    "    device_infos = device_manager.DeviceInfos\n",
    "\n",
    "    # Find the scanner with the specified name\n",
    "    scanner = None\n",
    "    for device_info in device_infos:\n",
    "        if device_info.Properties(\"Name\").Value == scanner_name:\n",
    "            scanner = device_info.Connect()\n",
    "            break\n",
    "\n",
    "    if scanner is None:\n",
    "        print(f\"Scanner '{scanner_name}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Set the desired scanning parameters (e.g., DPI, color mode, format)\n",
    "    # For example, set the scan resolution to 300 DPI and use color scanning\n",
    "    properties = scanner.Items[1].Properties\n",
    "    for prop in properties:\n",
    "        if prop.Name == '6146':  # 6146 is the property ID for scan resolution (DPI)\n",
    "            prop.Value = 300\n",
    "        elif prop.Name == '6147':  # 6147 is the property ID for color mode (1: Color, 2: Grayscale, 4: Black and White)\n",
    "            prop.Value = 1\n",
    "\n",
    "    # Perform the scan and retrieve the scanned image\n",
    "    image = scanner.Items[1].Transfer()\n",
    "    temp_dir = create_temp_folder()\n",
    "    \n",
    "    # Save the scanned image to a file inside the temporary folder\n",
    "    image.SaveFile(f\"{temp_dir}/sheet9.jpg\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'Scanner Name' with the name of your desired scanner\n",
    "    scanner_name = \"HP Laser MFP 131 133 135-138\"\n",
    "    scan_without_dialog(scanner_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reference sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sheet(\"sheet2.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**student sheet**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "def preprocess_image(image_path):\n",
    "    # read image\n",
    "    reference = cv2.imread(image_path)\n",
    "    # Resize image\n",
    "    reference = cv2.resize(reference, (2480, 3507))\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform median filtering\n",
    "    median = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Apply adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized = clahe.apply(median)\n",
    "    \n",
    "    return reference,equalized\n",
    "def index_preprocess(image_path):\n",
    "    reference=cv2.imread(image_path)\n",
    "    reference=cv2.resize(reference, (2480,3507))\n",
    "    gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    normalized=normalize_brightness(gray)\n",
    "    median = cv2.medianBlur(normalized, 5)\n",
    "\n",
    "    return median\n",
    "def normalize_brightness(image):\n",
    "    # Compute the image's pixel distribution\n",
    "    hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
    "\n",
    "    # Determine the desired minimum and maximum pixel values based on the pixel distribution\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    desired_min = bins[np.argmax(cdf_normalized > 0.01 * cdf_normalized.max())]\n",
    "    desired_max = bins[np.argmax(cdf_normalized > 0.99 * cdf_normalized.max())]\n",
    "\n",
    "    # Normalize the brightness to the desired range of pixel values\n",
    "    normalized = cv2.normalize(image, None, alpha=desired_min, beta=desired_max, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def remove_noise(image):\n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return opened_image\n",
    "\n",
    "def find_contours(image, median=None):\n",
    "    # Threshold image\n",
    "    thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   \n",
    "    \n",
    "    if median is not None:\n",
    "        # Adaptive threshold to identify index numbers\n",
    "        adap_thresh = cv2.adaptiveThreshold(median, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 5)\n",
    "        index_contours, _ = cv2.findContours(adap_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return contours, index_contours, adap_thresh\n",
    "    else:\n",
    "        return contours\n",
    "\n",
    "def find_largest_contour(contours):\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    return largest_contour\n",
    "\n",
    "def filter_contours(contours, largest_contour,normalized):\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        if y > largest_contour[0][0][1] and 1.5 <= w / h <= 2.5:\n",
    "            roi = normalized[y:y+h, x:x+w]\n",
    "            avg_intensity = np.mean(roi)\n",
    "        #     # Define threshold for minimum intensity\n",
    "            min_intensity_thresh = 150\n",
    "            max_intensity_thresh=200\n",
    "        #     # # If intensity or texture is below threshold, discard contour\n",
    "            if min_intensity_thresh < avg_intensity < max_intensity_thresh:\n",
    "    \n",
    "                area = cv2.contourArea(contour)\n",
    "                hull = cv2.convexHull(contour)\n",
    "                hull_area = cv2.contourArea(hull)\n",
    "                if hull_area > 0:\n",
    "                    solidity = float(area)/hull_area\n",
    "                    if solidity > 0.5 or solidity==0.5:\n",
    "                        epsilon = cv2.arcLength(contour,True)\n",
    "                        if epsilon >100:\n",
    "                            filtered_contours.append(contour)\n",
    "    return filtered_contours\n",
    "\n",
    "def sort_index_contours(index_contours, adap_thresh, reference):\n",
    "    index_sorted_contours = []\n",
    "\n",
    "    index_contours = sorted(index_contours, key=cv2.contourArea, reverse=True)\n",
    "    third_largest_contour = index_contours[2] if len(index_contours) >= 3 else None\n",
    "\n",
    "    if third_largest_contour is not None:\n",
    "        [x, y, w, h] = cv2.boundingRect(third_largest_contour)\n",
    "        index_roi = adap_thresh[y:y+h, x:x+w]\n",
    "        index_rgb=reference[y:y+h, x:x+w]\n",
    "        sorted_contours, _ = cv2.findContours(index_roi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        index_sorted_contours = sorted(sorted_contours, key=lambda c: (cv2.boundingRect(c)[0], cv2.boundingRect(c)[1]))\n",
    "\n",
    "    return index_sorted_contours,index_rgb\n",
    "\n",
    "def filter_index_contours(index_sorted_contours,normalized,index_rgb):\n",
    "    index_numbers=[]\n",
    "    for contour in index_sorted_contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        hull = cv2.convexHull(contour)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        if hull_area > 0:\n",
    "            solidity = float(area)/hull_area\n",
    "            if solidity > 0.5:\n",
    "                epsilon = cv2.arcLength(contour,True)\n",
    "                if epsilon >100:\n",
    "                    roi = normalized[y:y+h, x:x+w]\n",
    "                    avg_intensity = np.mean(roi)\n",
    "                    min_intensity_thresh = 100\n",
    "                    max_intensity_thresh=280\n",
    "                    if min_intensity_thresh < avg_intensity < max_intensity_thresh and 1.5 <= w / h <= 2.5:\n",
    "                            cv2.rectangle(index_rgb, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "                            if 150<y<190:\n",
    "                                index_numbers.append('0')\n",
    "                            elif 195<y<225:\n",
    "                                index_numbers.append('1')\n",
    "                            elif 230<y<265:\n",
    "                                index_numbers.append('2')\n",
    "                            elif 270<y<300:\n",
    "                                index_numbers.append('3')\n",
    "                            elif 305<y<340:\n",
    "                                index_numbers.append('4')\n",
    "                            elif 340<y<375:\n",
    "                                index_numbers.append('5')\n",
    "                            elif 380<y<415:\n",
    "                                index_numbers.append('6')\n",
    "                            elif 420<y<450:\n",
    "                                index_numbers.append('7')  \n",
    "                            elif 455<y<490:\n",
    "                                index_numbers.append('8')\n",
    "                            elif 495<y<530:\n",
    "                                index_numbers.append('9')   \n",
    "    index_numbers = int(''.join(map(str, index_numbers))) \n",
    "    print(index_numbers)  \n",
    "    return index_numbers\n",
    "def group_contours(contours):\n",
    "    # Define the ranges for grouping\n",
    "    range1 = (200, 550)\n",
    "    range2 = (600, 1000)\n",
    "    range3 = (1050, 1400)\n",
    "\n",
    "    # Group the contours based on x-value ranges\n",
    "    group1 = sorted([c for c in contours if range1[0] <= cv2.boundingRect(c)[0] <= range1[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "    group2 = sorted([c for c in contours if range2[0] <= cv2.boundingRect(c)[0] <= range2[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "    group3 = sorted([c for c in contours if range3[0] <= cv2.boundingRect(c)[0] <= range3[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "\n",
    "    concatenated_contours = group1 + group2 + group3\n",
    "    return concatenated_contours\n",
    "\n",
    "def process_contour(x, y, w, h, index, reference, student_answers, answer_contours=None):\n",
    "    answer = None  # Variable to store the answer\n",
    "\n",
    "    if (220 <= x <= 290) or (660 <= x <= 710) or (1084 <= x <= 1130):\n",
    "        answer = f'{index+1}.A'\n",
    "    elif (300 <= x <= 355) or (720 <= x <= 770) or (1140 <= x <= 1190):\n",
    "        answer = f'{index+1}.B'\n",
    "    elif (357 <= x <= 410) or (780 <= x <= 830) or (1200 <= x <= 1250):\n",
    "        answer = f'{index+1}.C'\n",
    "    elif (415 <= x <= 470) or (841 <= x <= 895) or (1260 <= x <= 1310):\n",
    "        answer = f'{index+1}.D'\n",
    "    elif (480 <= x <= 530) or (900 <= x <= 955) or (1320 <= x <= 1370):\n",
    "        answer = f'{index+1}.E'\n",
    "\n",
    "    if answer is not None:\n",
    "        student_answers.append(answer)\n",
    "        if answer_contours is not None:\n",
    "            answer_contours.append([x, y, w, h])\n",
    "            cv2.rectangle(reference, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "        else:\n",
    "            cv2.rectangle(reference, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "    \n",
    "    return reference\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def student_sheet(image_path):\n",
    "\n",
    "    reference,equalized= preprocess_image(image_path)\n",
    "    median=index_preprocess(image_path)\n",
    "    normalized = normalize_brightness(equalized)\n",
    "    opened_image = remove_noise(normalized)\n",
    "    contours,index_contours,adap_thresh = find_contours(opened_image,median)\n",
    "    index_sorted_contours,index_rgb=sort_index_contours(index_contours,adap_thresh,reference)\n",
    "    index_numbers=filter_index_contours(index_sorted_contours,normalized,index_rgb)\n",
    "    largest_contour=find_largest_contour(contours)\n",
    "    filtered_contours=filter_contours(contours,largest_contour,normalized)\n",
    "    concatenated_contours = group_contours(filtered_contours)\n",
    "\n",
    "    student_answers = []\n",
    "    answer_contours=[]\n",
    "    # Iterate over the contours\n",
    "    for index, contour in enumerate(concatenated_contours):\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        process_contour(x, y, w, h, index, reference, student_answers,answer_contours)\n",
    "    cv2.imwrite('query.jpg',reference)\n",
    "    print(student_answers)\n",
    "        # Convert the NumPy array to a PIL image\n",
    "    reference_image = Image.fromarray(reference)\n",
    "    return index_numbers,student_answers,reference_image,answer_contours\n",
    "\n",
    "def reference_sheet(image_path):\n",
    "\n",
    "    reference, equalized = preprocess_image(image_path)\n",
    "    normalized = normalize_brightness(equalized)\n",
    "    opened_image = remove_noise(normalized)\n",
    "    contours= find_contours(opened_image)\n",
    "    largest_contour=find_largest_contour(contours)\n",
    "    filtered_contours=filter_contours(contours,largest_contour,normalized)\n",
    "    concatenated_contours = group_contours(filtered_contours)\n",
    "\n",
    "    reference_answers = []\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for index, contour in enumerate(concatenated_contours):\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        process_contour(x,y,w,h, index, reference, reference_answers)\n",
    "     \n",
    "    cv2.imwrite('reference.jpg',reference)\n",
    "    return reference_answers\n",
    "\n",
    "def score(reference_answers,all_results):\n",
    "    index_numbers=[]\n",
    "    scores=[]\n",
    "    for i, result in enumerate(all_results):\n",
    "        reference=cv2.imread(all_results[i]['image_paths'])\n",
    "        score=0\n",
    "        for value_a in reference_answers:\n",
    "            for value_b in all_results[i]['student_answers']:\n",
    "                if value_a== value_b:\n",
    "                    score+=1\n",
    "                    answer_contours=all_results[i]['answer_contours']\n",
    "                    # Answer is correct, draw green bounding box\n",
    "                    cv2.rectangle(reference, (answer_contours[i][0], answer_contours[i][1]), (answer_contours[i][0] + answer_contours[i][2], answer_contours[i][1] + answer_contours[i][3]), (0, 255, 0), 2)\n",
    "                    break\n",
    "                else:\n",
    "                    # Answer is incorrect, draw red bounding box\n",
    "                    cv2.rectangle(reference, (answer_contours[i][0], answer_contours[i][1]), (answer_contours[i][0] + answer_contours[i][2], answer_contours[i][1] + answer_contours[i][3]), (255, 0, 0), 2)\n",
    "                    break\n",
    "        index_numbers.append(all_results[i]['index_numbers'])\n",
    "        scores.append(score)\n",
    "    df=pd.DataFrame({\n",
    "    'Index No':[index_numbers],\n",
    "    'Score':[scores]\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_sheet(r\"C:\\Users\\Sam\\Desktop\\project\\ocr_code\\Automatic-test-scoring-system\\streamlit\\scanned_sheets\\sheet1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.C', '3.C', '4.C', '5.A', '6.A', '7.B', '8.B', '9.A', '12.C', '13.B', '16.B', '21.A', '22.A', '23.B', '26.D', '27.A', '28.A', '29.B', '30.C', '31.A', '32.C', '33.D', '35.B', '36.D', '37.B', '38.B', '39.C', '40.A', '41.A', '42.A', '45.C', '46.B', '47.C', '48.A', '52.A', '53.B', '54.C', '55.B', '56.A', '57.C', '58.C', '62.C', '64.B', '66.C', '70.A', '72.B', '74.A', '76.B', '80.B', '81.B', '85.C', '86.C', '87.C', '90.A', '94.A', '98.C', '100.B', '105.B', '106.B', '108.C', '109.B', '111.A', '113.B', '119.B', '121.B', '123.C', '125.C', '127.A', '129.B', '131.B', '133.B', '139.C', '141.C', '143.A', '147.A', '149.A', '151.B', '156.B', '157.B', '160.A', '162.C']\n"
     ]
    }
   ],
   "source": [
    "folder = [r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\Automatic-test-scoring-system\\streamlit\\scanned_sheets\\sheet1.jpg']\n",
    "all_results = []\n",
    "\n",
    "for i in folder:\n",
    "    index_numbers,student_answers,reference_image,answer_contours = student_sheet(i)\n",
    "    all_results.append({\"index_numbers\": index_numbers, \"student_answers\": student_answers})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.C',\n",
       " '3.C',\n",
       " '4.C',\n",
       " '5.A',\n",
       " '6.A',\n",
       " '7.B',\n",
       " '8.B',\n",
       " '9.A',\n",
       " '12.C',\n",
       " '13.B',\n",
       " '16.B',\n",
       " '21.A',\n",
       " '22.A',\n",
       " '23.B',\n",
       " '26.D',\n",
       " '27.A',\n",
       " '28.A',\n",
       " '29.B',\n",
       " '30.C',\n",
       " '31.A',\n",
       " '32.C',\n",
       " '33.D',\n",
       " '35.B',\n",
       " '36.D',\n",
       " '37.B',\n",
       " '38.B',\n",
       " '39.C',\n",
       " '40.A',\n",
       " '41.A',\n",
       " '42.A',\n",
       " '45.C',\n",
       " '46.B',\n",
       " '47.C',\n",
       " '48.A',\n",
       " '52.A',\n",
       " '53.B',\n",
       " '54.C',\n",
       " '55.B',\n",
       " '56.A',\n",
       " '57.C',\n",
       " '58.C',\n",
       " '62.C',\n",
       " '64.B',\n",
       " '66.C',\n",
       " '70.A',\n",
       " '72.B',\n",
       " '74.A',\n",
       " '76.B',\n",
       " '80.B',\n",
       " '81.B',\n",
       " '85.C',\n",
       " '86.C',\n",
       " '87.C',\n",
       " '90.A',\n",
       " '94.A',\n",
       " '98.C',\n",
       " '100.B',\n",
       " '105.B',\n",
       " '106.B',\n",
       " '108.C',\n",
       " '109.B',\n",
       " '111.A',\n",
       " '113.B',\n",
       " '119.B',\n",
       " '121.B',\n",
       " '123.C',\n",
       " '125.C',\n",
       " '127.A',\n",
       " '129.B',\n",
       " '131.B',\n",
       " '133.B',\n",
       " '139.C',\n",
       " '141.C',\n",
       " '143.A',\n",
       " '147.A',\n",
       " '149.A',\n",
       " '151.B',\n",
       " '156.B',\n",
       " '157.B',\n",
       " '160.A',\n",
       " '162.C']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[0]['student_answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_numbers,student_answers,reference_image,answer_contours = student_sheet(r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8', '2', '8', '1', '9']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "answers=reference_sheet(r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet3.jpg')\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "for i,value in enumerate(answers):\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=all_results[0]['student_answers']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def find_dominant_intensity(contours, normalized):\n",
    "    intensity_values = []\n",
    "\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        roi = normalized[y:y+h, x:x+w]\n",
    "        avg_intensity = np.mean(roi)\n",
    "        intensity_values.append(avg_intensity)\n",
    "\n",
    "    # Convert intensity_values to a 1D array\n",
    "    intensity_values = np.array(intensity_values).reshape(-1, 1)\n",
    "\n",
    "    # Apply K-means clustering with k=1 to find the dominant intensity value\n",
    "    kmeans = KMeans(n_clusters=1).fit(intensity_values)\n",
    "\n",
    "    dominant_intensity = kmeans.cluster_centers_[0][0]\n",
    "    return dominant_intensity\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4836aab9230707cf36e93c729ff9a67bdbebd51947e18404ed5a25d63daeec60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
