{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reference sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sheet(\"sheet2.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**student sheet**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "def preprocess_image(image_path):\n",
    "    # read image\n",
    "    reference = cv2.imread(image_path)\n",
    "    # Resize image\n",
    "    reference = cv2.resize(reference, (2480, 3507))\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform median filtering\n",
    "    median = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Apply adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized = clahe.apply(median)\n",
    "    \n",
    "    return reference,equalized\n",
    "def index_preprocess(image_path):\n",
    "    reference=cv2.imread(image_path)\n",
    "    reference=cv2.resize(reference, (2480,3507))\n",
    "    gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    normalized=normalize_brightness(gray)\n",
    "    median = cv2.medianBlur(normalized, 5)\n",
    "\n",
    "    return median\n",
    "def normalize_brightness(image):\n",
    "    # Compute the image's pixel distribution\n",
    "    hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
    "\n",
    "    # Determine the desired minimum and maximum pixel values based on the pixel distribution\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    desired_min = bins[np.argmax(cdf_normalized > 0.01 * cdf_normalized.max())]\n",
    "    desired_max = bins[np.argmax(cdf_normalized > 0.99 * cdf_normalized.max())]\n",
    "\n",
    "    # Normalize the brightness to the desired range of pixel values\n",
    "    normalized = cv2.normalize(image, None, alpha=desired_min, beta=desired_max, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def remove_noise(image):\n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return opened_image\n",
    "\n",
    "def find_contours(image, median=None):\n",
    "    # Threshold image\n",
    "    thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   \n",
    "    \n",
    "    if median is not None:\n",
    "        # Adaptive threshold to identify index numbers\n",
    "        adap_thresh = cv2.adaptiveThreshold(median, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 5)\n",
    "        index_contours, _ = cv2.findContours(adap_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return contours, index_contours, adap_thresh\n",
    "    else:\n",
    "        return contours\n",
    "\n",
    "def find_largest_contour(contours):\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    return largest_contour\n",
    "\n",
    "def filter_contours(contours, largest_contour,normalized):\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        if y > largest_contour[0][0][1] and 1.5 <= w / h <= 2.5:\n",
    "            roi = normalized[y:y+h, x:x+w]\n",
    "            avg_intensity = np.mean(roi)\n",
    "        #     # Define threshold for minimum intensity\n",
    "            min_intensity_thresh = 90\n",
    "            max_intensity_thresh=160\n",
    "        #     # # If intensity or texture is below threshold, discard contour\n",
    "            if min_intensity_thresh < avg_intensity < max_intensity_thresh:\n",
    "    \n",
    "                area = cv2.contourArea(contour)\n",
    "                hull = cv2.convexHull(contour)\n",
    "                hull_area = cv2.contourArea(hull)\n",
    "                if hull_area > 0:\n",
    "                    solidity = float(area)/hull_area\n",
    "                    if solidity > 0.5 or solidity==0.5:\n",
    "                        epsilon = cv2.arcLength(contour,True)\n",
    "                        if epsilon >100:\n",
    "                            filtered_contours.append(contour)\n",
    "    return filtered_contours\n",
    "\n",
    "def sort_index_contours(index_contours, adap_thresh, reference):\n",
    "    index_sorted_contours = []\n",
    "\n",
    "    index_contours = sorted(index_contours, key=cv2.contourArea, reverse=True)\n",
    "    third_largest_contour = index_contours[2] if len(index_contours) >= 3 else None\n",
    "\n",
    "    if third_largest_contour is not None:\n",
    "        [x, y, w, h] = cv2.boundingRect(third_largest_contour)\n",
    "        index_roi = adap_thresh[y:y+h, x:x+w]\n",
    "        index_rgb=reference[y:y+h, x:x+w]\n",
    "        sorted_contours, _ = cv2.findContours(index_roi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        index_sorted_contours = sorted(sorted_contours, key=lambda c: (cv2.boundingRect(c)[0], cv2.boundingRect(c)[1]))\n",
    "\n",
    "    return index_sorted_contours,index_rgb\n",
    "\n",
    "def filter_index_contours(index_sorted_contours,normalized,index_rgb):\n",
    "    index_numbers=[]\n",
    "    for contour in index_sorted_contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        hull = cv2.convexHull(contour)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        if hull_area > 0:\n",
    "            solidity = float(area)/hull_area\n",
    "            if solidity > 0.5:\n",
    "                epsilon = cv2.arcLength(contour,True)\n",
    "                if epsilon >100:\n",
    "                    roi = normalized[y:y+h, x:x+w]\n",
    "                    avg_intensity = np.mean(roi)\n",
    "                    min_intensity_thresh = 100\n",
    "                    max_intensity_thresh=280\n",
    "                    if min_intensity_thresh < avg_intensity < max_intensity_thresh and 1.5 <= w / h <= 2.5:\n",
    "                            cv2.rectangle(index_rgb, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "                            if 150<y<190:\n",
    "                                index_numbers.append('0')\n",
    "                            elif 195<y<225:\n",
    "                                index_numbers.append('1')\n",
    "                            elif 230<y<265:\n",
    "                                index_numbers.append('2')\n",
    "                            elif 270<y<300:\n",
    "                                index_numbers.append('3')\n",
    "                            elif 305<y<340:\n",
    "                                index_numbers.append('4')\n",
    "                            elif 340<y<375:\n",
    "                                index_numbers.append('5')\n",
    "                            elif 380<y<415:\n",
    "                                index_numbers.append('6')\n",
    "                            elif 420<y<450:\n",
    "                                index_numbers.append('7')  \n",
    "                            elif 455<y<490:\n",
    "                                index_numbers.append('8')\n",
    "                            elif 495<y<530:\n",
    "                                index_numbers.append('9')   \n",
    "    index_numbers = int(''.join(map(str, index_numbers)))   \n",
    "    return index_numbers\n",
    "def group_contours(contours):\n",
    "    # Define the ranges for grouping\n",
    "    range1 = (200, 550)\n",
    "    range2 = (600, 1000)\n",
    "    range3 = (1050, 1400)\n",
    "\n",
    "    # Group the contours based on x-value ranges\n",
    "    group1 = sorted([c for c in contours if range1[0] <= cv2.boundingRect(c)[0] <= range1[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "    group2 = sorted([c for c in contours if range2[0] <= cv2.boundingRect(c)[0] <= range2[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "    group3 = sorted([c for c in contours if range3[0] <= cv2.boundingRect(c)[0] <= range3[1]], key=lambda c: cv2.boundingRect(c)[1])\n",
    "\n",
    "    concatenated_contours = group1 + group2 + group3\n",
    "    return concatenated_contours\n",
    "\n",
    "def process_contour(x, y, w, h, index, reference, student_answers, answer_contours=None):\n",
    "    answer = None  # Variable to store the answer\n",
    "\n",
    "    if (220 <= x <= 290) or (660 <= x <= 710) or (1084 <= x <= 1130):\n",
    "        answer = f'{index+1}.A'\n",
    "    elif (300 <= x <= 355) or (720 <= x <= 770) or (1140 <= x <= 1190):\n",
    "        answer = f'{index+1}.B'\n",
    "    elif (357 <= x <= 410) or (780 <= x <= 830) or (1200 <= x <= 1250):\n",
    "        answer = f'{index+1}.C'\n",
    "    elif (415 <= x <= 470) or (841 <= x <= 895) or (1260 <= x <= 1310):\n",
    "        answer = f'{index+1}.D'\n",
    "    elif (480 <= x <= 530) or (900 <= x <= 955) or (1320 <= x <= 1370):\n",
    "        answer = f'{index+1}.E'\n",
    "\n",
    "    if answer is not None:\n",
    "        student_answers.append(answer)\n",
    "        if answer_contours is not None:\n",
    "            answer_contours.append([x, y, w, h])\n",
    "            cv2.rectangle(reference, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "        else:\n",
    "            cv2.rectangle(reference, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "    \n",
    "    return reference\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def student_sheet(image_path):\n",
    "\n",
    "    reference,equalized= preprocess_image(image_path)\n",
    "    median=index_preprocess(image_path)\n",
    "    normalized = normalize_brightness(equalized)\n",
    "    opened_image = remove_noise(normalized)\n",
    "    contours,index_contours,adap_thresh = find_contours(opened_image,median)\n",
    "    index_sorted_contours,index_rgb=sort_index_contours(index_contours,adap_thresh,reference)\n",
    "    index_numbers=filter_index_contours(index_sorted_contours,normalized,index_rgb)\n",
    "    largest_contour=find_largest_contour(contours)\n",
    "    filtered_contours=filter_contours(contours,largest_contour,normalized)\n",
    "    concatenated_contours = group_contours(filtered_contours)\n",
    "\n",
    "    student_answers = []\n",
    "    answer_contours=[]\n",
    "    # Iterate over the contours\n",
    "    for index, contour in enumerate(concatenated_contours):\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        process_contour(x, y, w, h, index, reference, student_answers,answer_contours)\n",
    "    cv2.imwrite('sheet.jpg',reference)\n",
    "        # Convert the NumPy array to a PIL image\n",
    "    reference_image = Image.fromarray(reference)\n",
    "    return index_numbers,student_answers,reference_image,answer_contours\n",
    "\n",
    "def reference_sheet(image_path):\n",
    "\n",
    "    reference, equalized = preprocess_image(image_path)\n",
    "    normalized = normalize_brightness(equalized)\n",
    "    opened_image = remove_noise(normalized)\n",
    "    contours= find_contours(opened_image)\n",
    "    largest_contour=find_largest_contour(contours)\n",
    "    filtered_contours=filter_contours(contours,largest_contour,normalized)\n",
    "    concatenated_contours = group_contours(filtered_contours)\n",
    "\n",
    "    reference_answers = []\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for index, contour in enumerate(concatenated_contours):\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        process_contour(x,y,w,h, index, reference, reference_answers)\n",
    "     \n",
    "    cv2.imwrite('reference.jpg',reference)\n",
    "    return reference_answers\n",
    "\n",
    "def score(reference_answers,all_results,reference):\n",
    "    score=0\n",
    "    index_numbers=[]\n",
    "    scores=[]\n",
    "    for i, value in enumerate(reference_answers):\n",
    "        if value== all_results[i]['student_answers']:\n",
    "            score+=1\n",
    "            answer_contours=all_results[i]['answer_contours']\n",
    "            # Answer is correct, draw green bounding box\n",
    "            cv2.rectangle(reference, (answer_contours[i][0], answer_contours[i][1]), (answer_contours[i][0] + answer_contours[i][2], answer_contours[i][1] + answer_contours[i][3]), (0, 255, 0), 2)\n",
    "        else:\n",
    "            # Answer is incorrect, draw red bounding box\n",
    "            cv2.rectangle(reference, (answer_contours[i][0], answer_contours[i][1]), (answer_contours[i][0] + answer_contours[i][2], answer_contours[i][1] + answer_contours[i][3]), (255, 0, 0), 2)\n",
    "        index_numbers.append(all_results[i]['index_numbers'])\n",
    "        scores.append(score)\n",
    "    df=pd.DataFrame({\n",
    "    'Index No':[index_numbers],\n",
    "    'Score':[scores]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = (r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet1.jpg', r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet5.jpg')\n",
    "all_results = []\n",
    "\n",
    "for i in folder:\n",
    "    index_numbers,student_answers,reference_image,answer_contours = student_sheet(i)\n",
    "    all_results.append({\"index_numbers\": index_numbers, \"student_answers\": student_answers})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_numbers,student_answers,reference_image,answer_contours = student_sheet(r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8', '2', '8', '1', '9']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "answers=reference_sheet(r'C:\\Users\\Sam\\Desktop\\project\\ocr_code\\sheet3.jpg')\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "for i,value in enumerate(answers):\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=all_results[0]['student_answers']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def find_dominant_intensity(contours, normalized):\n",
    "    intensity_values = []\n",
    "\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        roi = normalized[y:y+h, x:x+w]\n",
    "        avg_intensity = np.mean(roi)\n",
    "        intensity_values.append(avg_intensity)\n",
    "\n",
    "    # Convert intensity_values to a 1D array\n",
    "    intensity_values = np.array(intensity_values).reshape(-1, 1)\n",
    "\n",
    "    # Apply K-means clustering with k=1 to find the dominant intensity value\n",
    "    kmeans = KMeans(n_clusters=1).fit(intensity_values)\n",
    "\n",
    "    dominant_intensity = kmeans.cluster_centers_[0][0]\n",
    "    return dominant_intensity\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4836aab9230707cf36e93c729ff9a67bdbebd51947e18404ed5a25d63daeec60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
